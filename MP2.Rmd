---
title: "SDS/CSC 293 Mini-Project 2: Multiple Regression"
author: "Group XX: WRITE YOUR NAMES HERE"
date: "Wednesday, March 6^th^, 2019"
output:
  html_document:
    code_folding: hide
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---

```{r setup, include=FALSE}
# Load all your packages here:
library(tidyverse)
library(scales)

# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 16/2, fig.height = 9/2
)

# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

You will be submiting an entry to Kaggle's [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/){target="_blank"} by fitting a **multiple regression** model $\hat{f}(x)$.



***



# EDA

Read in data provided by Kaggle for this competition. They are organized in the `data/` folder of this RStudio project:

```{r}
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
```

Before performing any model fitting, you should always conduct an exploratory data analysis. This will help guide and inform your model fitting. 

## Look at your data!

Always, ALWAYS, **ALWAYS** start by looking at your raw data. This gives you visual sense of what information you have to help build your predictive models. To get a full description of each variable, read the data dictionary in the `data_description.txt` file in the `data/` folder.

Note that the following code chunk has `eval = FALSE` meaning "don't evaluate this chunk with knitting" because `.Rmd` files won't knit if they include a `View()`:

```{r, eval = FALSE}
View(training)
glimpse(training)

View(test)
glimpse(test)
```

In particular, pay close attention to the variables and variable types in the
`sample_submission.csv`. Your submission must match this exactly.

```{r}
glimpse(sample_submission)
```

## Data wrangling

As much as possible, try to do all your data wrangling here:

```{r}
training1 <- training %>%
  select(Id, SalePrice, GrLivArea, HouseStyle)

test1 <- test %>%
  select(Id, GrLivArea, HouseStyle)

training1_1 <- training1 %>%
  mutate(log10_SalePrice = log10(SalePrice),
         log10_GrLivArea = log10(GrLivArea))

pretend_train <- training1_1 %>%
  sample_frac(0.75)
pretend_test <- training1_1 %>%
  anti_join(pretend_train, by="Id")

glimpse(pretend_train)
glimpse(pretend_test)

```



***



# Minimally viable product

## Model fitting

```{r}
# 1. Fit model to training data
model_1_formula <- as.formula("SalePrice ~ GrLivArea + HouseStyle")
model_1 <- lm(model_1_formula, data = training1)

# 2.a) Extract regression table with confidence intervals
model_1 %>%
  broom::tidy(conf.int = TRUE)

# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
  broom::augment()
fitted_points_1

# 2.c) Extract model summary info
model_1 %>%
  broom::glance()

# 3. Make predictions on test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
  broom::augment(newdata = test1)
predicted_points_1


```


## Estimate of your Kaggle score

```{r}
# 1. Fit model to pretend training data
model_1_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + HouseStyle")
model_1 <- lm(model_1_formula, data = pretend_train)

# 2.a) Extract regression table with confidence intervals
model_1 %>%
  broom::tidy(conf.int = TRUE)

# 2.b) Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
  broom::augment()
fitted_points_1

# 2.c) Extract model summary info
model_1 %>%
  broom::glance()

# 3. Make predictions on pretend test data. Compare this to use of broom::augment()
# for fitted_points()
predicted_points_1 <- model_1 %>%
  broom::augment(newdata = pretend_test)
predicted_points_1

# Save predictions in pretend_test data frame
pretend_test <- pretend_test %>% 
  mutate(log10_SalePrice_hat = predicted_points_1$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat
      )

pretend_test <- pretend_test %>% 
      mutate(
        residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
        residual_sq = residual^2
      ) 

rmlse <- pretend_test %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)

rmlse
```


## Create your submission CSV

```{r}
submission <- sample_submission %>% 
  mutate(SalePrice = mean(training$SalePrice))

write_csv(submission, path = "data/submission_mvp.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](score_screenshot.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores





***





# Due diligence

## Model fitting

```{r}

```


## Estimate of your Kaggle score

```{r}

```


## Create your submission CSV

```{r}
submission <- sample_submission %>% 
  mutate(SalePrice = mean(training$SalePrice))

write_csv(submission, path = "data/submission_due_diligence.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](score_screenshot.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores





***





# Reaching for the stars

## Model fitting

```{r}

```


## Estimate of your Kaggle score

```{r}

```


## Create your submission CSV

```{r}
submission <- sample_submission %>% 
  mutate(SalePrice = mean(training$SalePrice))

write_csv(submission, path = "data/submission_reach_for_stars.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](score_screenshot.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores






***





# Point of diminishing returns

## Model fitting

```{r}

```


## Estimate of your Kaggle score

```{r}

```


## Create your submission CSV

```{r}
submission <- sample_submission %>% 
  mutate(SalePrice = mean(training$SalePrice))

write_csv(submission, path = "data/submission_diminishing_returns.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](score_screenshot.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores
