---
title: "SDS/CSC 293 Mini-Project 2: Multiple Regression"
author: "Group 11: Nashshaba Nawaz & Cassidy Maher"
date: "Wednesday, March 6^th^, 2019"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---

```{r setup, include=FALSE}
# Load all your packages here:
library(tidyverse)
library(scales)

# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 16/2, fig.height = 9/2
)

# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

You will be submiting an entry to Kaggle's [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/){target="_blank"} by fitting a **multiple regression** model $\hat{f}(x)$.



***



# EDA

Read in data provided by Kaggle for this competition. They are organized in the `data/` folder of this RStudio project:

```{r}
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
```



## Data wrangling

As much as possible, try to do all your data wrangling here:

```{r}
training<- training %>%
  mutate(log10_SalePrice = log10(SalePrice),
         log10_GrLivArea = log10(GrLivArea))

test <- test %>%
  mutate(log10_GrLivArea = log10(GrLivArea))

pretend_train <- training %>%
  sample_frac(0.75)
pretend_test <- training %>%
  anti_join(pretend_train, by="Id")

# Convert all character variables to factors for better modeling
pretend_train <- pretend_train %>% mutate_if(is.character, as.factor)
pretend_test <- pretend_test %>% mutate_if(is.character, as.factor)
```



***

# Minimally viable product

## Model fitting
```{r}
# MINIMALLY VIABLE PRODUCT
# 1. Fit model to training data
model_1_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + HouseStyle")
model_1 <- lm(model_1_formula, data = training)

# Fit MVP model on actual test data and submit to Kaggle
predicted_points <- model_1 %>%
  broom::augment(newdata = test)

test <- test %>% 
  mutate(log10_SalePrice_hat = predicted_points$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)
```

## Create your submission CSV
```{r}
submission <- test %>%
  mutate(SalePrice = SalePrice_hat) %>%
  select(Id, SalePrice)

write.csv(submission, "data/submission_mvp.csv", row.names = F)
```

## Screenshot of your Kaggle score
![](first_submission.png){ width=100% }

***


# Due diligence
Obtain an estimate $\widehat{RMLSE}$ that closely matches the RMLSE that Kaggle returns.

```{r}
# Calculate RMLSE for MVP model with one numeric and one categorical predictor - 0.2564427

# Make predictions on pretend test data. 
predicted_points_1 <- model_1 %>%
  broom::augment(newdata = pretend_test)

# Save predictions in pretend_test data frame
pretend_test <- pretend_test %>% 
  mutate(log10_SalePrice_hat = predicted_points_1$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)

pretend_test <- pretend_test %>% 
      mutate(residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
        residual_sq = residual^2) 

rmlse1 <- pretend_test %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)
rmlse1
```


The estimated RMLSE from the pretend test data is 0.256 as compared to the actual Kaggle score of 0.253. These are very close!

***


# Reaching for the stars


```{r}
# REACHING FOR THE STARS

# Fit model with three arbitrarily chosen numerical and three categorical predictors to pretend training data
model_2_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + OverallQual + LotArea +
                              HouseStyle + Neighborhood + SaleCondition")
model_2 <- lm(model_2_formula, data = pretend_train)

# Make predictions on pretend test data
predicted_points_2 <- model_2 %>%
  broom::augment(newdata = pretend_test)

# Save predictions in pretend_test data frame
pretend_test <- pretend_test %>% 
  mutate(log10_SalePrice_hat = predicted_points_2$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)

pretend_test2 <- pretend_test %>% 
      mutate(residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
             residual_sq = residual^2) 

# Calculate RMLSE - 0.1734234
rmlse2 <- pretend_test2 %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)
rmlse2 

# COMPARE TO RMLSE FROM MINIMALLY VIABLE PRODUCT
# The RMLSE for the model with three categorical and three predictor variables has a smaller RMLSE than the model with only one each of numeric and categorical predictors (0.246 vs 0.173).
```

```{r}
# Do actual prediction on all of training data using the reaching for the stars model
model_2 <- lm(model_2_formula, data = training)

predicted_points2 <- model_2 %>%
  broom::augment(newdata = test)
```

## Create your submission CSV

```{r}
test2 <- test %>%
  mutate(log10_SalePrice_hat = predicted_points2$.fitted,
         SalePrice = 10^log10_SalePrice_hat)

submission2 <- test2 %>%
  select(Id, SalePrice)

write_csv(submission2, path = "data/submission_reach_for_stars.csv")
```


## Screenshot of your Kaggle score

![](second_submission.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.16273. This is very close to what our RMLSE hat of 0.1676 that we calculated up above.


***





# Point of diminishing returns

## Model fitting

```{r}

```


## Estimate of your Kaggle score

```{r}

```


## Create your submission CSV

```{r}
submission <- sample_submission %>% 
  mutate(SalePrice = mean(training$SalePrice))

write_csv(submission, path = "data/submission_diminishing_returns.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](score_screenshot.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores
