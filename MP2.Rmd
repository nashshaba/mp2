---
title: "SDS/CSC 293 Mini-Project 2: Multiple Regression"
author: "Group 11: Nashshaba Nawaz & Cassidy Maher"
date: "Wednesday, March 6^th^, 2019"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---

```{r setup, include=FALSE}
# Load all your packages here:
library(tidyverse)
library(scales)
library(gridExtra)

# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 16/2, fig.height = 9/2
)

# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

You will be submiting an entry to Kaggle's [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/){target="_blank"} by fitting a **multiple regression** model $\hat{f}(x)$.



***



# EDA

Read in data provided by Kaggle for this competition. They are organized in the `data/` folder of this RStudio project:

```{r}
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
```

We further analyzed the data by conducting univariate exploratory visualizations of outcome and all predictor variables used throughout the project. We also conducted multivariate exploratory visualizations of the *relationship* between the outcome and predictor variables. Since there are a lot of predictor variables, including a plot for each would make it difficult for a person to read the output file. 

## Data wrangling

As much as possible, try to do all your data wrangling here:

```{r}
training<- training %>%
  mutate(log10_SalePrice = log10(SalePrice),
         log10_GrLivArea = log10(GrLivArea),
         MSSubClass = as.factor(MSSubClass))

test <- test %>%
  mutate(log10_GrLivArea = log10(GrLivArea),
         MSSubClass = as.factor(MSSubClass))

training <- training %>% mutate_if(is.character, as.factor)
test <- test %>% mutate_if(is.character, as.factor)

```

## Visualizations

A multivariate exploratory visualization of the *relationship* between the outcome and predictor variable.

```{r}
plot1 <- ggplot(training, aes(x = log10_GrLivArea, y = log10_SalePrice)) +
  geom_point() +
  labs(x = "log10(Above ground living area in square feet)", 
       y = "log10(Sale price in USD)",
       title = "SalePrice against GrLivArea")
```

```{r}
plot2 <- ggplot(training, aes(x = HouseStyle, y = log10_SalePrice)) +
  geom_boxplot(fill =  "darkolivegreen1") +
  labs(x = "Style of Dwelling", 
       y = "log10(Sale price in USD)",
       title = "SalePrice against HouseStyle")
```

```{r}
grid.arrange(plot1, plot2, ncol=2)
```



***

# Minimally viable product

## Model fitting
```{r}
# MINIMALLY VIABLE PRODUCT
# 1. Fit model to training data
model_1_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + HouseStyle")
model_1 <- lm(model_1_formula, data = training)

# Fit MVP model on actual test data and submit to Kaggle
predicted_points <- model_1 %>%
  broom::augment(newdata = test)

test <- test %>% 
  mutate(log10_SalePrice_hat = predicted_points$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)
```

## Create your submission CSV
```{r}
submission <- test %>%
  mutate(SalePrice = SalePrice_hat) %>%
  select(Id, SalePrice)

write.csv(submission, "data/submission_mvp.csv", row.names = F)
```

## Screenshot of your Kaggle score
![](first_submission.png){ width=100% }

***


# Due diligence
Obtain an estimate $\widehat{RMLSE}$ that closely matches the RMLSE that Kaggle returns.

```{r}
# Calculate RMLSE for MVP model with one numeric and one categorical predictor - 0.2564427

training <- training %>% 
  sample_frac(1) %>% 
  mutate(fold = rep(1:5, length = n())) %>% 
  arrange(fold)

  #RMLSE <- rep(0, 5)
  for(j in 1:5){
    pretend_training <- training %>% 
      filter(fold != j)
    pretend_test <- training %>% 
      filter(fold == j)
    
    # Fit model on pretend training
    model_1_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + HouseStyle")
    model_1 <- lm(model_1_formula, data = pretend_training)

    # Make predictions on pretend test data. 
    predicted_points_1 <- model_1 %>%
    broom::augment(newdata = pretend_test)
    
    # Save predictions in pretend_test data frame
    pretend_test <- pretend_test %>% 
    mutate(log10_SalePrice_hat = predicted_points_1$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)
    
    RMLSE[j] <- pretend_test %>% 
      mutate(
        residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
        residual_sq = residual^2
      ) %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)
  }
  
RMLSE_hat <- mean(RMLSE)

RMLSE_hat
```


The estimated RMLSE from the pretend test data is 0.256 as compared to the actual Kaggle score of 0.253. These are very close!

***


# Reaching for the stars


```{r}
# REACHING FOR THE STARS

# Fit model with three arbitrarily chosen numerical and three categorical predictors to pretend training data
model_2_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + OverallQual + LotArea +
                              HouseStyle + Neighborhood + SaleCondition")
model_2 <- lm(model_2_formula, data = pretend_train)

# Make predictions on pretend test data
predicted_points_2 <- model_2 %>%
  broom::augment(newdata = pretend_test)

# Save predictions in pretend_test data frame
pretend_test <- pretend_test %>% 
  mutate(log10_SalePrice_hat = predicted_points_2$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)

pretend_test2 <- pretend_test %>% 
      mutate(residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
             residual_sq = residual^2) 

# Calculate RMLSE - 0.1734234
rmlse2 <- pretend_test2 %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)
rmlse2 

# COMPARE TO RMLSE FROM MINIMALLY VIABLE PRODUCT
# The RMLSE for the model with three categorical and three predictor variables has a smaller RMLSE than the model with only one each of numeric and categorical predictors (0.246 vs 0.173).
```

```{r}
# Do actual prediction on all of training data using the reaching for the stars model
model_2 <- lm(model_2_formula, data = training)

predicted_points2 <- model_2 %>%
  broom::augment(newdata = test)
```

## Create your submission CSV

```{r}
test2 <- test %>%
  mutate(log10_SalePrice_hat = predicted_points2$.fitted,
         SalePrice = 10^log10_SalePrice_hat)

submission2 <- test2 %>%
  select(Id, SalePrice)

write_csv(submission2, path = "data/submission_reach_for_stars.csv")
```


## Screenshot of your Kaggle score

![](second_submission.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.16273. This is very close to what our RMLSE hat of 0.1676 that we calculated up above.


***





# Point of diminishing returns

## Model fitting

```{r}
# REACHING FOR THE STARS

# Fit model with three arbitrarily chosen numerical and three categorical predictors to pretend training data
model_3_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + OverallQual + LotArea +
                              HouseStyle + Neighborhood + SaleCondition + Condition1 + OverallCond + YearBuilt +
                              CentralAir + KitchenQual + Functional + Fireplaces + WoodDeckSF")
model_3 <- lm(model_3_formula, data = pretend_train)

# Make predictions on pretend test data
predicted_points_3 <- model_3 %>%
  broom::augment(newdata = pretend_test)

# Save predictions in pretend_test data frame
pretend_test <- pretend_test %>% 
  mutate(log10_SalePrice_hat = predicted_points_3$.fitted,
        SalePrice_hat = 10^log10_SalePrice_hat)

pretend_test3 <- pretend_test %>% 
      mutate(residual = log(SalePrice + 1) - log(SalePrice_hat + 1),
             residual_sq = residual^2) 

# Calculate RMLSE - 0.1734234
rmlse3 <- pretend_test3 %>% 
      summarize(
        MLSE = mean(residual_sq),
        RMLSE = sqrt(MLSE)
      ) %>% 
      pull(RMLSE)
rmlse3
```


## Estimate of your Kaggle score

```{r}
MASS::stepAIC(model_3, direction = "both")
```


## Create your submission CSV

```{r}
predicted_points3 <- model_3 %>%
  broom::augment(newdata = test)

test3 <- test %>%
  mutate(log10_SalePrice_hat = predicted_points3$.fitted,
         SalePrice = 10^log10_SalePrice_hat)

submission3 <- test3 %>%
  select(Id, SalePrice)

write_csv(submission3, path = "data/submission_diminishing_returns.csv")
```


## Screenshot of your Kaggle score

Our score based on our submission's "Root Mean Squared Logarithmic Error" was 0.42918.

![](third_submission.png){ width=100% }


## Comparisons of estimated scores and Kaggle scores
