---
title: "mp2"
author: "Nashshaba Nawaz"
date: "2/27/2019"
output: 
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---

```{r setup, include=FALSE}
# Load all your packages here:
library(tidyverse)
library(scales)
library(broom)
library(stringr)

# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 16/2, fig.height = 9/2
)

# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

# Data

Read in data provided by Kaggle for this competition. They are organized in the `data/` folder of this RStudio project:

```{r}
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
```

## Look at data!

```{r, eval = FALSE}
View(training)
glimpse(training)

View(test)
glimpse(test)
```

Submission must match `sample_submission.csv` exactly.

```{r}
glimpse(sample_submission)
```
## Data wrangling


```{r}
training <- training %>% 
  select(Id, GrLivArea, HouseStyle, SalePrice)
test <- test %>% 
  select(Id, GrLivArea,HouseStyle)
```

## Visualizations

A univariate exploratory visualization of the outcome variable:

```{r}
ggplot(training, aes(x = SalePrice)) +
  geom_histogram() +
  labs(x = "Sale price in USD", title = "Outcome variable: sale price")
```

Given that the outcome variable:

1. Is Very skewed
1. Has to be greater than 0

I will:

1. Create a temporary outcome variable `log10_SalePrice` by running `log10(SalePrice)`. So a house that is one million dollars = 10^6^ will be 6.
1. Do all model fitting and predictions.
1. Return to the original outcome variable by "un-log10" the data

```{r}
training <- training %>% 
  mutate(log10_SalePrice = log10(SalePrice))
```

```{r}
ggplot(training, aes(x = log10_SalePrice)) +
  geom_histogram() +
  labs(x = "log10(Sale price in USD)", title = "Temporary outcome variable: log10(sale price)")
```

A univariate exploratory visualization of the predictor variables:

```{r}
ggplot(training, aes(x = GrLivArea)) +
  geom_histogram() +
  labs(x = "Above ground living area in square feet", title = "Predictor variable: living area")

ggplot(training, aes(x = HouseStyle)) +
  geom_bar() +
  labs(x = "Above ground living area in square feet", title = "Predictor variable: living area")
```



```{r}
training <- training %>% 
  mutate(log10_GrLivArea = log10(GrLivArea))
test <- test %>% 
  mutate(log10_GrLivArea = log10(GrLivArea))
```

```{r}
ggplot(training, aes(x = log10_GrLivArea)) +
  geom_histogram() +
  labs(x = "log10(Above ground living area in square feet)", title = "New predictor variable: log10(living area)")
```

A multivariate exploratory visualization of the *relationship* between the outcome and predictor variable.

```{r}
ggplot(training, aes(x = log10_GrLivArea, y = log10_SalePrice,colour = factor(HouseStyle))) +
  geom_point() +
  facet_grid(.~HouseStyle,scales='free')+
  labs(x = "log10(Above ground living area in square feet)", 
       y = "log10(Sale price in USD)",
       title = "Relationship of temporary outcome and predictor variable")
```
## Crossvalidation from scratch

Implement crossvalidation from scratch here. In other words, don't use an existing function, but rather program your own. 

```{r}
pretend_train <- training %>%
  sample_frac(0.75)
pretend_test <- test %>%
  anti_join(pretend_train, by="Id")

glimpse(pretend_train)
glimpse(pretend_test)

```
```{r}
# Fit model to taining data
model_1_formula <- as.formula("log10_SalePrice ~ log10_GrLivArea + HouseStyle")
model_1 <- lm(model_1_formula, data = pretend_train)

#Extract regression table with confidence intervals
model_1 %>%
  broom::tidy(conf.int = TRUE)

#Extract point-by-point info of points used to fit model
fitted_points_1 <- model_1 %>%
  broom::augment()
fitted_points_1

#Extract model summary info
model_1 %>%
  broom::glance()

#Make predictions on test data. Compare this to use of broom::augment() for fitted_points()
predicted_points_1 <- model_1 %>%
  broom::augment(newdata = pretend_test)
predicted_points_1


```


